{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with TensorFlow API\n",
    "\n",
    "To get this running, go to models/research dir and run the command: \"protoc object_detection/protos/*.protos --python_out=.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import sys, os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot\n",
    "import imageio\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Setting up the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_dir_path = './models/research'\n",
    "models_dir_path = './models/research/object_detection'\n",
    "sys.path.append(research_dir_path)\n",
    "sys.path.append(models_dir_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importing the actual API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./models/research/object_detection\\utils\\visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2739, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\IPython\\core\\events.py\", line 73, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\", line 160, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 308, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\matplotlib\\pyplot.py\", line 232, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\matplotlib\\__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "import object_detection\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_utils"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Setting the model the model and the labels for the detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "model_ckpt = '%s/%s/frozen_inference_graph.pb' % (models_dir_path, model_name)\n",
    "labels = '%s/data/mscoco_label_map.pbtxt' % (models_dir_path)\n",
    "num_classes = 100"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here I get the graph, the key point was the ParseFromString function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph = tf.Graph()\n",
    "with main_graph.as_default():\n",
    "    api_graph = tf.GraphDef()\n",
    "    with tf.gfile.GFile(model_ckpt, 'rb') as file:\n",
    "        serialized = file.read()\n",
    "        api_graph.ParseFromString(serialized)\n",
    "        tf.import_graph_def(api_graph, name='')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using some function from the API to get the labels and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(labels)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes = num_classes)\n",
    "categories_indexes = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Object Detection on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, im = cap.read()\n",
    "    cv2.imshow('Object Detection', cv2.resize(im, (800, 600)))\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with main_graph.as_default():\n",
    "    with tf.Session(graph=main_graph) as sess:\n",
    "        while True:\n",
    "            #The Tensors from the graph\n",
    "            ret, arr_image = cap.read()\n",
    "            \n",
    "            arr_image_expanded = np.expand_dims(arr_image, axis = 0)\n",
    "            image_tensor = main_graph.get_tensor_by_name('image_tensor:0')\n",
    "        \n",
    "            detection_boxes = main_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        \n",
    "            detection_scores = main_graph.get_tensor_by_name('detection_scores:0')\n",
    "        \n",
    "            detection_classes = main_graph.get_tensor_by_name('detection_classes:0')\n",
    "        \n",
    "            num_detections = main_graph.get_tensor_by_name('num_detections:0')\n",
    "            #The name of the video, in the same dir of the notebook\n",
    "            \n",
    "        \n",
    "            #We capture the exception so it can take the max of frames before an error\n",
    "            feed = {image_tensor: arr_image_expanded}\n",
    "            (boxes, scores, classes, num_detections) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections], feed_dict=feed)\n",
    "            \n",
    "            vis_utils.visualize_boxes_and_labels_on_image_array(arr_image, np.squeeze(boxes), np.squeeze(classes).astype(np.int32), np.squeeze(scores), categories_indexes, use_normalized_coordinates = True, line_thickness = 8)\n",
    "            \n",
    "            cv2.imshow('Object Detection', cv2.resize(arr_image, (800, 600)))\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
